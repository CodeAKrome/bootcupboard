{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bee98ea-a390-451a-baf3-ec7f56f10343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:38:53] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyle/anaconda3/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "import torch\n",
    "torch.set_default_device(\"cpu\")\n",
    "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1e7d19-bf58-4a3a-ac6c-94c4573cbf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d01710-f141-47ff-8250-59fb02932793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index import download_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0572061d-1465-45c6-a6b6-2b476fb4e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFReader = download_loader(\"PDFReader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a0908d-a814-4430-95cf-ec70e4d8a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d03f75fd-8aa7-4a5d-96e8-861bc76c7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load_data(file=Path(\"voyager.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e40b18-537e-43dd-a5e0-018582f1464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pdf_documents = [document.text for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62555da0-522f-47ed-bd51-59638fbcf431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VOYAGER : An Open-Ended Embodied Agent\\nwith Large Language Models\\nGuanzhi Wang1 2, Yuqi Xie3, Yunfan Jiang4∗, Ajay Mandlekar1∗,\\nChaowei Xiao1 5, Yuke Zhu1 3, Linxi Fan1†, Anima Anandkumar1 2†\\n1NVIDIA,2Caltech,3UT Austin,4Stanford,5ASU\\n∗Equal contribution†Equal advising\\nhttps://voyager.minedojo.org\\nAbstract\\nWe introduce VOYAGER , the first LLM-powered embodied lifelong learning agent\\nin Minecraft that continuously explores the world, acquires diverse skills, and\\nmakes novel discoveries without human intervention. V OYAGER consists of three\\nkey components: 1) an automatic curriculum that maximizes exploration, 2) an\\never-growing skill library of executable code for storing and retrieving complex\\nbehaviors, and 3) a new iterative prompting mechanism that incorporates environ-\\nment feedback, execution errors, and self-verification for program improvement.\\nVOYAGER interacts with GPT-4 via blackbox queries, which bypasses the need for\\nmodel parameter fine-tuning. The skills developed by VOYAGER are temporally\\nextended, interpretable, and compositional, which compounds the agent’s abilities\\nrapidly and alleviates catastrophic forgetting. Empirically, VOYAGER shows\\nstrong in-context lifelong learning capability and exhibits exceptional proficiency\\nin playing Minecraft. It obtains 3.3×more unique items, travels 2.3×longer\\ndistances, and unlocks key tech tree milestones up to 15.3×faster than prior SOTA.\\nVOYAGER is able to utilize the learned skill library in a new Minecraft world to\\nsolve novel tasks from scratch, while other techniques struggle to generalize.\\nFigure 1: VOYAGER discovers new Minecraft items and skills continually by self-driven exploration,\\nsignificantly outperforming the baselines. X-axis denotes the number of prompting iterations.\\n1arXiv:2305.16291v1  [cs.AI]  25 May 2023'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pdf_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca362cba-75bd-489c-a7c0-fcb0e495480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M i n e  W o o d   L o g\\nM a k e  C r a f t i n g  T a b l e\\nC r a f t  S t o n e  S w o r d\\nC r a f t  S h i e l d\\nM a k e  F u r n a c e\\nC o o k  S t e a k\\nC o m b a t  Z o m b i e     M i n e  W o o d  L o gM a k e  C r a f t i n g  T a b l eC o m b a t  \\nZ o m b i e\\nM i n e  D i a m o n d\\nN e w  \\nT a s kC o d e  a s  \\nA c t i o n sR e f i n e  P r o g r a mE n v  F e e d b a c k\\nE x e c u t i o n  E r r o r sU p d a t e  \\nE x p l o r a t i o n  \\nP r o g r e s sS k i l l  \\nR e t r i e v a l\\nA d d  N e w  S k i l lA u t o m a t i c  C u r r i c u l u mI t e r a t i v e  P r o m p t i n g  M e c h a n i s mS k i l l  L i b r a r y\\nE n v i r o n m e n tS e l f - V e r i f i c a t i o n\\nFigure 2: VOYAGER consists of three key components: an automatic curriculum for open-ended\\nexploration, a skill library for increasingly complex behaviors, and an iterative prompting mechanism\\nthat uses code as action space.\\n1 Introduction\\nBuilding generally capable embodied agents that continuously explore, plan, and develop new skills\\nin open-ended worlds is a grand challenge for the AI community [ 1–5]. Classical approaches\\nemploy reinforcement learning (RL) [ 6,7] and imitation learning [ 8–10] that operate on primitive\\nactions, which could be challenging for systematic exploration [ 11–15], interpretability [ 16–18], and\\ngeneralization [ 19–21]. Recent advances in large language model (LLM) based agents harness the\\nworld knowledge encapsulated in pre-trained LLMs to generate consistent action plans or executable\\npolicies [ 16,22,19]. They are applied to embodied tasks like games and robotics [ 23–27], as well as\\nNLP tasks without embodiment [ 28–30]. However, these agents are not lifelong learners that can\\nprogressively acquire, update, accumulate, and transfer knowledge over extended time spans [ 31,32].\\nLet us consider Minecraft as an example. Unlike most other games studied in AI [ 33,34,10],\\nMinecraft does not impose a predefined end goal or a fixed storyline but rather provides a unique\\nplayground with endless possibilities [ 23]. Minecraft requires players to explore vast, procedurally\\ngenerated 3D terrains and unlock a tech tree using gathered resources. Human players typically start\\nby learning the basics, such as mining wood and cooking food, before advancing to more complex\\ntasks like combating monsters and crafting diamond tools. We argue that an effective lifelong learning\\nagent should have similar capabilities as human players: (1) propose suitable tasks based on its\\ncurrent skill level and world state, e.g., learn to harvest sand and cactus before iron if it finds itself in\\na desert rather than a forest; (2) refine skills based on environmental feedback and commit mastered\\nskills to memory for future reuse in similar situations (e.g. fighting zombies is similar to fighting\\nspiders); (3) continually explore the world and seek out new tasks in a self-driven manner.\\nTowards these goals, we introduce VOYAGER , the first LLM-powered embodied lifelong learning\\nagent to drive exploration, master a wide range of skills, and make new discoveries continually\\nwithout human intervention in Minecraft. VOYAGER is made possible through three key modules\\n(Fig. 2): 1) an automatic curriculum that maximizes exploration; 2) a skill library for storing\\nand retrieving complex behaviors; and 3) a new iterative prompting mechanism that generates\\nexecutable code for embodied control. We opt to use code as the action space instead of low-level\\nmotor commands because programs can naturally represent temporally extended and compositional\\nactions [ 16,22], which are essential for many long-horizon tasks in Minecraft. VOYAGER interacts\\nwith a blackbox LLM (GPT-4 [ 35]) through prompting and in-context learning [ 36–38]. Our approach\\nbypasses the need for model parameter access and explicit gradient-based training or finetuning.\\nMore specifically, VOYAGER attempts to solve progressively harder tasks proposed by the automatic\\ncurriculum , which takes into account the exploration progress and the agent’s state. The curriculum\\nis generated by GPT-4 based on the overarching goal of “discovering as many diverse things as\\npossible”. This approach can be perceived as an in-context form of novelty search [39,40].VOYAGER\\n2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pdf_documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa9773-8c7f-4825-8017-bca809a9a8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Feb 07, 21:38:55] #> Note: Output directory .ragatouille/colbert/indexes/voyager already exists\n",
      "\n",
      "\n",
      "[Feb 07, 21:38:55] #> Will delete 1 files already at .ragatouille/colbert/indexes/voyager in 20 seconds...\n",
      "[Feb 07, 21:39:16] [0] \t\t #> Encoding 197 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/Users/kyle/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "100%|██████████| 4/4 [00:07<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:39:24] [0] \t\t avg_doclen_est = 156.88832092285156 \t len(local_sample) = 197\n",
      "[Feb 07, 21:39:24] [0] \t\t Creating 2,048 partitions.\n",
      "[Feb 07, 21:39:24] [0] \t\t *Estimated* 30,906 embeddings.\n",
      "[Feb 07, 21:39:24] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/voyager/plan.json ..\n"
     ]
    }
   ],
   "source": [
    "RAG.index(\n",
    "    collection=list_pdf_documents,\n",
    "    index_name=\"voyager\",\n",
    "    max_document_length=256,\n",
    "    split_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b6525-26c2-4701-897c-b7bb22bafe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253960cf-9426-4156-b3a8-cda5eab8c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = RAG.search(query=\"Minecraft\", k=k, index_name=\"voyager\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92fc70b-33ae-4229-b5db-733bb2afb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
